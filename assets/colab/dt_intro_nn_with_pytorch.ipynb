{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlmQIFSLZDdc"
      },
      "source": [
        "# Duckietown Intro to Neural Nets with PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B1SZliCuVWB"
      },
      "source": [
        "\n",
        "## Prerequisites\n",
        "\n",
        "**Step 1:** install pytorch.\n",
        "\n",
        "\n",
        "**Important:** the following cell is only needed for this notebook. If you're installing pytorch on your own computer (which you totally can, even without a NVIDIA GPU), then please use the instructions from here: https://pytorch.org/get-started/locally/\n",
        "\n",
        "Note that this will take a few seconds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V-jaj13tl07"
      },
      "source": [
        "# http://pytorch.org/\n",
        "!pip install torch==1.13.0 torchvision==0.14.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkCJV_gfXUYJ"
      },
      "source": [
        "**Step 2:** import and check that torch works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRMEa74queCT"
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.rand(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iYd9zKqX29Y"
      },
      "source": [
        "**Step 3:** Convert from numpy to torch and back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RrRuCa2X2uS"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a_npy = np.eye(4)\n",
        "print (a_npy)\n",
        "\n",
        "a_tor = torch.from_numpy(a_npy) # convert numpy to torch Tensor\n",
        "print (a_tor)\n",
        "\n",
        "b_npy = a_tor.numpy() # convert Tensor back to numpy\n",
        "print (b_npy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY8M4tyoX4kj"
      },
      "source": [
        "**Step 4:** Notice that if you change the data EITHER in numpy or torch, you're changing it in both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoKov5Tluf1M"
      },
      "source": [
        "a_npy[0,3] = 99 # we're only changing the numpy array\n",
        "\n",
        "a_tor[1,3] = 123 # we're only changing the torch Tensor\n",
        "\n",
        "print (a_npy) # no we're not\n",
        "print (a_tor)\n",
        "print (b_npy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv_zr57vZffq"
      },
      "source": [
        "**Step 5:** Other than that, PyTorch is just like Numpy... but all the things are called different names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrscWsCfZFxV"
      },
      "source": [
        "# These things do the same thing, but have different names and one is a property,\n",
        "# the other one is a function.\n",
        "\n",
        "print (a_npy.shape)\n",
        "print (a_tor.size())\n",
        "\n",
        "# Most (not all) things that you can do in Numpy, you can also do in PyTorch,\n",
        "# but you have to google what they are called\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIZfifIsaNJk"
      },
      "source": [
        "## Neural Nets\n",
        "\n",
        "**Step 6:** This is how you define a neural net in PyTorch\n",
        "\n",
        "**IMPORTANT:** read the comments. It's crucial that you understand what's happening. If something is unclear, ask on stack overflow with the label #neural-nets. It is easy to make simple mistakes when working with neural networks, so it is better to ask for help as early as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnNsk4fsaCNy"
      },
      "source": [
        "import torch # we already did this, but just in case you want to\n",
        "# copy-paste this code block\n",
        "\n",
        "import torch.nn as nn # functions for neural nets, like layers and loss function\n",
        "import torch.nn.functional as F #  these are helper functions liks sigmoid, relu, etc\n",
        "\n",
        "# what's missing here is the import for the optimizer\n",
        "\n",
        "\n",
        "# you need to create a class that inherits from nn.Module\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Here in the init function you only create the layers that you want to\n",
        "        # use later on. You're not actually connecting them to anything here.\n",
        "        # So you can create them in any order.\n",
        "\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # 3 color channels input, 6 convolutional kernels -> 6 channels output,\n",
        "        # and also 5x5 square kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        # after applying this to a 3x32x32 image without padding or stride,\n",
        "        # the result will be 6x28x28\n",
        "\n",
        "        # max pooling with a 2x2 moving window\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # after applying this to the 6x28x28 image, the result will be\n",
        "        # 6x14x14 (the channels are not affected)\n",
        "\n",
        "        # 6 channels input, 16 convolutional kernels -> 16 channels output,\n",
        "        # and also 5x5 square kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # after applying this to a 6x14x14 image without padding or stride,\n",
        "        # the result will be 16x10x10\n",
        "\n",
        "        # Later in the actual forward pass, we will apply the maxpooling twice,\n",
        "        # but we only have to define it once, because it doesn't have any para-\n",
        "        # meters that we're backpropping through.\n",
        "        # So we know that we will apply MaxPool2d(2,2) again to the 16x10x10 image.\n",
        "        # Therefore the output of the convolutional layers will be 16x5x5.\n",
        "\n",
        "\n",
        "        # This layer definition requires that you did the convolution math.\n",
        "        # The final \"image\" will be 5 by 5 pixels and 16 channels deep, therefore\n",
        "        # the input is 16 * 5 * 5.\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "\n",
        "        # The sizes of these layers are _completely_ arbitrary.\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "\n",
        "        # ultimately our ouput will be a 10-element vector for each input image\n",
        "        # which corresponds to a one-hot encoding of a 0-9 integer\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # This function is for a single forward pass through the network.\n",
        "        # So you get the input, pass it through all the layers you defined above\n",
        "        # (!important, don't define any new layers here) and then return the final\n",
        "        # result.\n",
        "\n",
        "        # Apply, in that order: convolutional layer 1 (3,6,5), ReLU, MaxPool2d(2,2)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Apply, in that order: convolutional layer 2 (6,16,5), ReLU, MaxPool2d(2,2)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # The input is still 3-dimensional (shape: 16x5x5). Here we transform it\n",
        "        # into a vector of size (16*5*5 = 400)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # Pass it through fully connected layer 1 and then through ReLU\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Pass it through fully connected layer 2 and then through ReLU\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Pass it through the last layer WITHOUT RELU and return it\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# here we just instantiate the network, so we can go use it.\n",
        "net = Net()\n",
        "\n",
        "# and make sure it's using 32-bit floats (\"Float\"), not 64-bit floats (\"Double\")\n",
        "net = net.float()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNUV5Bu3pVmb"
      },
      "source": [
        "**Step 7 (optional):** print the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrqvdiBMpU8m"
      },
      "source": [
        "print (net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAGV4xUeq3NJ"
      },
      "source": [
        "**Step 8:** Test the network with random input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGRaNhUhq3tP"
      },
      "source": [
        "# create a single image (note how the color channel is in the front)\n",
        "dummy_input = np.random.uniform(low=0, high=1, size=(3,32,32)).astype(np.float32)\n",
        "\n",
        "# convert to Tensor:\n",
        "dummy_tensor = torch.from_numpy(dummy_input)\n",
        "\n",
        "print (\"old size:\", dummy_tensor.size())\n",
        "\n",
        "# IMPORTANT. torch works in batches. You can have a batch size of 1 (if it's only)\n",
        "# a single image, but you need to add the dimension (which you want to become the\n",
        "# new axis 0):\n",
        "\n",
        "dummy_tensor = dummy_tensor.unsqueeze(0)\n",
        "\n",
        "print (\"new size:\", dummy_tensor.size(),\"<--- see? There's a new first dimension!\")\n",
        "\n",
        "# now we can feed it into the network:\n",
        "prediction = net(dummy_tensor)\n",
        "\n",
        "print (\"prediction size:\",prediction.size(),\"<-- The output has the \" \\\n",
        "       \"same first dimension. That's the batch size!\")\n",
        "\n",
        "print (\"\")\n",
        "print (prediction)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlw_Lpuov2kR"
      },
      "source": [
        "**Step 9:** Start optimizing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVPURycv3My"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# instead of Mean Squared Error (MSE or \"L2\") loss we use CE loss here because\n",
        "# this has great performance if your output is categorical and ideally in range [0,1]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# stochastic gradient descent... (There are better options)\n",
        "# and feed the net.parameters() to the optimizer - that's all the optimizable\n",
        "# parameters in the netwoprk\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzosG1H9pWhI"
      },
      "source": [
        "**Step 10:** Do a trial run of the optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU8wzIYQ4fYb"
      },
      "source": [
        "# let's stack (\"concatenate\" - \"torch.cat()\") 4 images into a minibatch:\n",
        "inputs = torch.cat([dummy_tensor, dummy_tensor, dummy_tensor, dummy_tensor], dim=0).float()\n",
        "print (\"inputs.size()\", inputs.size())\n",
        "\n",
        "# let's make some dummy labels - notice how it's only the batch dimension\n",
        "labels = torch.zeros(4).long()\n",
        "print (\"labels.size()\",labels.size())\n",
        "\n",
        "# zero the parameter gradients (always do this during learning before every forward pass)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# predict the outputs\n",
        "outputs = net(inputs)\n",
        "print (\"outputs.size()\", outputs.size())\n",
        "\n",
        "# now we have a problem: our labels are unidimensional, but the prediction is\n",
        "# 10-dimensional (on purpose)... what do?\n",
        "# Answer: you can either spread out the ground truth into one-hot encoding\n",
        "# Or: you can use a loss function that can accept both: CrossEntropy.\n",
        "\n",
        "loss = criterion(outputs, labels) # apply the loss function, notice the format of\n",
        "# loss(prediction, ground_truth) <-- that's important\n",
        "\n",
        "# calculate the backpropagation values\n",
        "loss.backward()\n",
        "\n",
        "# apply the backprop values according to the optimizer\n",
        "optimizer.step()\n",
        "\n",
        "# And print loss - very important - PLOT THIS! If this doesn't go a lot lower\n",
        "# then you are done and the network is converged\n",
        "print (\"Loss:\", loss.item())\n",
        "\n",
        "# Now run this cell couple of times and watch the loss go down."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIqVJoFc-Jtr"
      },
      "source": [
        "## Let's train on real data\n",
        "\n",
        "**Step 11:** Load the CIFAR-10 dataset\n",
        "\n",
        "(It's very small and you can download it directly through torch, without manually downloading it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK-SL4jepWLb"
      },
      "source": [
        "# torchvision has some helper functions for image-based dataset\n",
        "import torchvision\n",
        "\n",
        "# we want to apply certain things to all of our images - that's what transforms do\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# we would like all of our incoming images to: become a torch Tensor\n",
        "# (instead of a numpy array) and we want to normalize all images\n",
        "# normalization: img = (img-mean)/standard_deviation\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # parameters for\n",
        "# the normalization are mean and std for each channel\n",
        "\n",
        "\n",
        "# download the training part of the CIFAR-10 dataset and apply transforms\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "# wrap that into a multi-threaded data loader for quicker multi-CPU data loading\n",
        "# and for being able to shuffle the data and sample whole batches and not just\n",
        "# single elements\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "# same thing for the test dataset\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n",
        "# these are the names of the labels, corresponding to 0,1,2,3, etc.\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3R7PjD_naz"
      },
      "source": [
        "**Step 12:** ALWAYS verify your data!\n",
        "\n",
        "Before running _any_ experiment, always look at your data and make sure it's what you expect it to be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keA8Z3BmpXjb"
      },
      "source": [
        "print (\"dataset length:\",len(trainset))\n",
        "\n",
        "image, label = trainset[0]\n",
        "\n",
        "print (\"single image (size):\",image.size()) # <-- this is a tensor\n",
        "print (\"single label:\",label) # <-- this is not, but it will be if we use the \"trainloader\" from above\n",
        "\n",
        "\n",
        "### now let's actually -look- at the images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images using the trainloader\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images - make a grid of 4\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M00f0zcJBRU0"
      },
      "source": [
        "print (images.min(), images.mean(), images.max()) # important to verify your distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3xcPfEdBv7f"
      },
      "source": [
        "## Let's glue it all together\n",
        "\n",
        "**Step 13:** Let's actually run the optimization in a loop with the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlXmDQvxp-t_"
      },
      "source": [
        "print (\"[epoch, line of data]\")\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[{}, {}] \\tloss: {}'.format(\n",
        "                epoch + 1,\n",
        "                i + 1,\n",
        "                running_loss / 2000)\n",
        "                )\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-GoezmKDAUM"
      },
      "source": [
        "... Now go to the cells bellow (Step 14), and inspect the results. They're not very good, right?\n",
        "\n",
        "Then, copy the entire previous cell below and run again (to see how the loss converges to something if you run it long enough). Run Step 14 again. See how much better that was? Not perfect, but better.\n",
        "\n",
        "(Obviously, in a real setting, you'd use some kind of loop instead of copying the cell.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwy6XDPeqOeG"
      },
      "source": [
        "# insert code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Rr6QLMDaj9"
      },
      "source": [
        "**Step 14:** Inspection - manually check your predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw0ZJEo_Dhqf"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9H_rNT7Dj4b"
      },
      "source": [
        "# now let's get the net's predictions\n",
        "outputs = net(images)\n",
        "\n",
        "# argmax the 10 dimensions into one\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# get the names of the labels for each int label\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkBge1WNEaq7"
      },
      "source": [
        "**Step 15:** Actually get a numerical evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdU9PGW-D2OU"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# If we're not learning anything then we use the torch.no_grad() environment.\n",
        "# In this environment no gradients are ever calculated.\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"Accuracy of the network on the \" \\\n",
        "      \"10000 test images: {}%\".format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_tnvMSIHcG5"
      },
      "source": [
        "~60% is not very accurate. You can do much better.\n",
        "\n",
        "## \"Homework\"\n",
        "\n",
        "**Goal: improve the score, i.e. the test set accuracy**\n",
        "\n",
        "We won't verify how you do on this, so this is just so you can learn about neural networks.\n",
        "\n",
        "Ideas:\n",
        "- try out a different optimizer\n",
        "- try out more training epochs\n",
        "- try out a bigger neural network (more hidden nodes or more layers)\n",
        "- try plotting the loss over time and stop training when the loss converges\n",
        "- (if you're fancy) try out dataset augmentation - that means applying more transformations to your images before feeding them to the network - like random rotation, random noise, etc. Here's a ist of all transforms: https://pytorch.org/docs/stable/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6U8lU-xgQyW"
      },
      "source": [
        "# Contributors\n",
        " - [Florian Golemo](https://fgolemo.github.io/)\n",
        " - [Bhairav Mehta](https://bhairavmehta95.github.io/)\n",
        " - [Charlie Gauthier](https://ca.linkedin.com/in/charlie-gauthier)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KD1W2-aVCfK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}